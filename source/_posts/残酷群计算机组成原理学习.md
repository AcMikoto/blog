---
title: 残酷群计算机组成原理学习
toc: true
date: 2022-02-23 23:09:32
updated:
tags:
- 计算机组成原理
categories:
- 计算机组成原理
---

# 残酷群计算机组成原理学习

## CPU分几级缓存？大小一般是多少？访问各级缓存需要的时间，需要多少CPU cycle的数量级

### CPU分几级缓存？
按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存、二级缓存以及三级缓存。
- L1：容量最小，速度最快，每个核都有L1缓存，此外针对指令和数据分为数据缓存和指令缓存
- L2：容量大于L1，速度慢于L1，每个核都有L2缓存
- L3：容量最大，速度最慢，多核共享。

### 缓存大小？
- L1：64 - 512KB
- L2：4 - 8 MB
- L3：10 - 64MB



### 访问时间？
- L1：约2 - 4个时钟周期，2ns左右
- L2：约10 - 20个时钟周期，10ns左右
- L3：约50 - 70个时钟周期，30ns左右

## C++静态库和动态库的区别

静态库：在链接阶段，会将汇编生成的目标文件.o与引用到的库一起链接打包到可执行文件中。因此对应链接方式称为静态链接。

静态库特点：
- 静态库对函数库的链接是放在编译时期完成的。
- 程序在运行时与函数库没有关系，即使删去库函数，也能正常运行，移植比较方便。
- 相对更浪费空间和资源，所有相关的目标文件都会被链接到一个可执行文件中。
- 如果静态库进行更新则应用该库的所有程序都需要重新编译（全量更新）

静态库文件后缀.a .lib

动态库：程序运行时由系统动态加载动态库到内存，供程序调用。系统只加载一次，多个程序共用，节省内存。

动态库特点：
- 动态库把一些库函数的链接载入推迟到程序运行时期。
- 可以实现进程间资源的共享（因此动态库也被称为共享库）
- 程序升级变得简单（动态库升级相当于升级里头的库函数？）
- 可以做到链接载入完全由程序员在程序代码中控制（显示调用）；

区别：
1. 时期
静态库在编译时连接，在链接时拷贝
动态库在运行时链接

2. 资源
静态库在每次使用时将全部连接金可执行程序，浪费资源
动态库在使用时访问动态库中的函数，节省资源

3. 更新升级
静态库更新，则每个使用该静态库的程序都需要更新，不易于更新升级
动态库仅更新自身，易于更新升级

4. 包含其他库
静态链接库不能再包含其他动态链接库
动态链接库可以包含其他动态链接库


## python中数据类型有哪些，list和tuple的区别

### python中的基本数据类型
python3中共有6个标准的数据类型：
- Number（数字）
- String（字符串）
- List（列表）
- Tuple（元组）
- Set（集合）
- Dictionary（字典）

其中
- 不可变数据：Number（数字）、String（字符串）、Tuple（元组）
- 可变数据： List（列表）、Dictionary（字典）、Set（集合）

### list和tuple的区别

1. 可修改性
- 列表是动态的，长度大小不固定，可以增删改（mutable），而元组是静态的，长度大小固定，无法增删改（immutable）
- 元组内嵌列表，列表元素本身可以变化，但无法修改元组元素，只能修改这个列表元素本身的值（增删改）
- 列表内嵌元组，元组本身不可变，但可以修改列表元素。

2. 列表和元组的存储空间
- 列表需要存储指针指向对应的元素
- 列表可变，因此会额外分配一些空间，而元组大小固定，存储空间也固定。

3. 列表和元组的性能
- 静态变量缓存、元组会更优：由于python对静态数据做一些资源缓存，一些变量不使用时会被回收，占用空间不大时python会暂时缓存这部分内存，下次创建同样大小元组时会被直接分配之前缓存的内存空间，大大加快程序的运行速度。
- 索引操作性能基本一致
- 增删改：列表更优，而元组必须通过新建一个新元组来完成。
- 创建空列表 [] 快于 list() 因为list（）是一个function call，Python的function call会创建stack并进行一系列参数检查的操作，而[]是一个内置C函数，直接调用效率更高。

4. 其它
- tuple可以作为set 或者 dict的key值，而list不行，因此我们用python写记忆化的时候可以先把list转为元组，参数列表里面写tuple然后转成list操作再转成tuple这样子，配合cache使用也很无敌。


## 什么是五级流水线，数据冒险是什么?

### 什么是五级流水线？
指令流水线是指将指令的处理过程拆分为若干个阶段，每个阶段硬件处理单元进行阶段处理，并行执行，用来加快指令的执行速度。指令的处理流程简单规划可以分为：从存储器中取出指令；翻译指令，使计算机知道指令是要怎么工作；\*执行指令，进行相应的指令执行。

五级流水线是指将指令流水线分为五个部分：取指（IF）；译码（ID）；执行（EX）；访存(访问存储器，MEM）；\*写回（数据写回到目标寄存器，write back）；


各个阶段的作用：
IF：从指令存储器中取出指令，同时确定下一条指令地址（指针指向下一条指令）
ID：翻译指令，让计算机知道指令是要干什么的，同时让计算机得出要使用的寄存器，或者让**立即数**进行拓展（方便指后续指令执行），亦或者（转移指令）给出转移目标寄存器与转移条件。
EX：执行指令，此阶段按照指令给定的内容进行执行
MEM：若为load/store指令，这个阶段就要访问存储器。此外，指令从EX向下执行到WB阶段。另外，这个阶段还要判断是否有异常要处理，如果有，那么就清除流水线，然后转移到异常处理例程入口地址处继续执行。
WB：将运算结果保存到目标寄存器


### 数据冒险是什么？

流水线技术之所以能够提高性能，本质上是利用了时间上的并行性，那它让原本应该先后执行的指令在时间上一定程度的并行起来，然后也会带来一些冲突和矛盾；

冒险：在流水线中，我们希望时钟周期都有一条指令进入流水线可以执行。但是在某些情况下，下一条指令无法按照预期进行执行，这种情况就被称为冒险。

冒险分为三种：

- 结构冒险：如果一条指令需要的硬件部分还在为之前的指令工作，而无法这条指令提供服务，那就导致了结构冒险（也称为资源冲突）
- 数据冒险：如果一条指令需要某数据而该数据正在被之前的指令操作，那么这条指令就无法执行，就导致了数据冒险（也称为数据相关性）
- 控制冒险：如果现在要执行哪条指令，是由之前指令的运行结果决定，而现之前的那条指令结果还没产生，就会导致控制冒险


## cpp: volatile和atomic的区别

### volatile

volatile: 关键字，意味着程序可能受到程序之外的因素影响，结合例子比较好说明
```
volatile int *p = ????;
int a, b;
a = *p;
b = *p;
```

使用说明：

一个非volatile值到volatile值的转换是无效果的。
要使用volatile语义访问非volatile对象，必须先将它的地址转换成指向volatile类型的指针，再通过指针访问该对象。
任何通过非volatile左值结果，对拥有volatile限定类型对象的尝试度或者写都会导致未定义行为

```
volatile int n = 1; // volatile 限定类型
int* p = (int*)&n;
int val = *p; // 未定义行为，这里是通过指针去访问volatile限定类型对象
```


如果不考虑volatile关键字，p是一个简单的int\*指针，下面两个赋值语句，只需要从内存中读取一次，因为读取后CPU寄存器中有这个值，之后直接复用该值，编译器会把两次访存的操作优化成一次。但是上述优化，是基于如果我们认为：我们没有在代码里改变p指向的内存地址的值，那么这个值一定不改变。

然而由于MMIP（Memory mapped I/O）的存在，假设p指向的内存是一个硬件设备，那么从p指向的内存读取数据伴随着可观测的副作用：硬件状态的修改。如此一来，若原代码的意愿是将硬件设备返回的两个连线int值分别保存在a 和 b中，由于编译器的优化，程序的行为会变得不符合预期。

总结来说，被volatile修饰的变量，在对其进行读写操作时，会引发一些可观测的副作用，而这些副作用是由程序之外的原因决定的。可以用volatile禁用优化


### atomic

std::atomic为C++ 11封装的原子数据类型。

原子数据类型：从功能上来看，简单地说，原子数据类型不会发生数据竞争，可以直接用在多线程中而不必我们用户对其进行添加互斥资源锁的类型。

atomic模板的实例化好全特化定义一个原子类型。若一个线程写入原子对象，同时另一线程从它读取，则行为良好定义。
对原子对象的访问可以建立线程间同步，并按照std::memory_order所对非原子内存访问定序
std::atomic即不可复制也不可移动。

示例：使用atomic_int 类型

```
#include <bits/stdc++.h>
using namespace std;

atomic_int iCount(0);

void threadfunc1() {
    for(int i = 0; i < 10; i ++) {
        printf("iCount: %d\n", iCount ++);
    }
}

void threadfunc2() {
    for(int i = 0; i < 10; i ++) {
        printf("%iCount: %d\n", iCount --);
    }
}

int main () {
    list<thread> lt;
    for(int i = 0; i < 10; i ++) {
        lt.push_back(thread(threadfunc1));
    }
    for(int i = 0; i < 10; i ++) {
        lt.push_back(thread(threadfunc2));
    }
    for(auto&& i: lt) {
        i.join();
    }
    int x = iCount.load(memory_order_relaxed);
    printf("finally iCount: %d\n", x);
}
```
最终输出x结果为0

使用普通 int类型

```
#include <bits/stdc++.h>
using namespace std;

int iCount(0);

void threadfunc1() {
    for(int i = 0; i < 10; i ++) {
        printf("iCount: %d\r\n", iCount ++);
        //iCount ++;
    }
}

void threadfunc2() {
    for(int i = 0; i < 10; i ++) {
        printf("iCount: %d\r\n", iCount --);
        //iCount --;
    }
}

int main () {
    list<thread> lt;
    for(int i = 0; i < 20; i ++) {
        lt.push_back(thread(threadfunc1));
    }
    for(int i = 0; i < 20; i ++) {
        lt.push_back(thread(threadfunc2));
    }
    for(auto&& i: lt) {
        i.join();
    }
    
    //int x = iCount.load(memory_order_relaxed);
    printf("finally iCount: %d\r\n", iCount);
}
```
结果不保证是0，通常不是0


## Python：什么是鸭子类型

鸭子模型 常见说法：当一只鸟走起来像鸭子，游泳起来像鸭子，叫起来也像鸭子，那么这只鸟就可以被称为鸭子

鸭子类型（duck typing）在程序设计中是动态类型的一种风格，这种风格中，一个对象有效的语义，不是由继承自特定的类型或者实现特定的接口，而是由“当前方法和属性的集合”决定

鸭子类型中，关注点主要在于对象的行为能做什么；而不是关注对象所属的类型。比如C++中函数参数类型固定，函数实现的方法固定，而python中函数参数可以不写类型名，实现的方法固定。

## 从内存里读一个byte计算机内部是怎么实现的

1. CPU核发出VA（virtual address）请求读取数据，TLB（translantion lookaside buffer）接收到该地址，TLB是MMU（Memory Managemant Unit）中的一块高速缓存（也是一种cache，是CPU和物理内存之间的cache），缓存最近查找过的VA对应的页表项，如果TLB中缓存了当前VA的页表项就不必去物理内存中读取页表项，否则需要去物理内存中读出页表项保存在TLB中，TLB缓存可以减少访问物理内存的次数。

2. 页表项中不仅保存着物理页面的基地址，还保存着权限和是否cache的标准，MMU首先检查权限位，如果没有访问权限，就引发一个异常给CPU核。然后检查是否允许cache，如果允许cache就气动cache与CPU核互操作。
3. 如果不允许cache，直接发出PA（Physical Address）从物理内存中读取数据到CPU核
4. 如果允许cache，则以VA为缩影到cache中查找是否缓存了要读取的数据，若已缓存（缓存命中）则直接返回给CPU核，若未缓存（缓存未命中）则从物理内存中读取并缓存到cache中。注意的是，cache并不是仅缓存CPU核需要的数据，而是吧相邻数据都读取来缓存，称为cache line


<!--more-->
